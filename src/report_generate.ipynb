{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYW6dfEdotMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def report_gen(y_pred, y_true, report_name=None, out_loc=\"report_llama\"):\n",
    "    # given predicted and true labels,\n",
    "    # generate the overall results and pertype analysis with misclassification\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    df_report = pd.DataFrame(\n",
    "        columns=[\"type\", \"precision\", \"recall\", \"f1-score\", \"support\"]\n",
    "    )\n",
    "\n",
    "    overall = {}\n",
    "    for t in report:\n",
    "        if t not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "            report[t][\"type\"] = t\n",
    "            df_report = pd.concat(\n",
    "                [df_report, pd.DataFrame(report[t], index=[0])], ignore_index=True\n",
    "            )\n",
    "        else:\n",
    "            overall[t] = report[t]\n",
    "\n",
    "    # extract misclassification details\n",
    "    dic = {}\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        if t not in dic:\n",
    "            dic[t] = {\"mis_to\": {}, \"mis_from\": {}}\n",
    "        if p not in dic:\n",
    "            dic[p] = {\"mis_to\": {}, \"mis_from\": {}}\n",
    "\n",
    "        if t != p:\n",
    "            dic[t][\"mis_to\"][p] = dic[t][\"mis_to\"].get(p, 0) + 1\n",
    "            dic[p][\"mis_from\"][t] = dic[p][\"mis_from\"].get(t, 0) + 1\n",
    "\n",
    "    def first_five(dic):\n",
    "        return sorted(dic.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "    df_report[\"mis_from_top5\"] = df_report.apply(\n",
    "        lambda x: first_five(dic[x[\"type\"]][\"mis_from\"]), axis=1\n",
    "    )  # precision\n",
    "    df_report[\"mis_to_top5\"] = df_report.apply(\n",
    "        lambda x: first_five(dic[x[\"type\"]][\"mis_to\"]), axis=1\n",
    "    )  # recall\n",
    "\n",
    "    # save results\n",
    "    if report_name is not None:\n",
    "        if not os.path.exists(out_loc):\n",
    "            os.mkdir(out_loc)\n",
    "\n",
    "        df_report.sort_values([\"f1-score\"], ascending=False).to_csv(\n",
    "            join(out_loc, \"results_per_type_{}.csv\".format(report_name))\n",
    "        )\n",
    "\n",
    "        with open(join(out_loc, \"overall_{}.json\".format(report_name)), \"w\") as outfile:\n",
    "            json.dump(overall, outfile)\n",
    "\n",
    "    return overall, df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data process and result\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def canonical_header(h, max_header_len=30):\n",
    "    \"\"\"Convert any header to its canonical form\"\"\"\n",
    "    h = str(h)\n",
    "    if len(h) > max_header_len:\n",
    "        return \"-\"\n",
    "    h = re.sub(r\"\\([^)]*\\)\", \"\", h)  # trim content in parentheses\n",
    "    h = re.sub(r\"([A-Z][a-z])\", r\" \\1\", h)  # insert a space before any Capital starts\n",
    "    words = list(\n",
    "        filter(lambda x: len(x) > 0, map(lambda x: x.lower(), re.split(\"\\W\", h)))\n",
    "    )\n",
    "    if len(words) <= 0:\n",
    "        return \"-\"\n",
    "    new_phrase = \"\".join([words[0]] + [x.capitalize() for x in words[1:]])\n",
    "    return new_phrase\n",
    "\n",
    "\n",
    "def extract_predictions_from_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Extract predictions and ground truth from JSONL files.\n",
    "    Applies canonical_header transformation to all column names.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                entry = json.loads(line)\n",
    "\n",
    "                # Extract the model output after \"assistant\\n\\n\"\n",
    "                sample = entry[\"sample\"]\n",
    "                matches = re.findall(\n",
    "                    r\"assistant\\n\\n(.*?)(?=assistant|$)\", sample, re.DOTALL\n",
    "                )\n",
    "\n",
    "                if matches:\n",
    "                    # Take the first prediction if multiple exist\n",
    "                    pred_text = matches[0].strip()\n",
    "                    try:\n",
    "                        pred_json = json.loads(pred_text)\n",
    "                        pred_cols = [\n",
    "                            canonical_header(col)\n",
    "                            for col in pred_json.get(\"colnames\", [])\n",
    "                        ]\n",
    "                    except json.JSONDecodeError:\n",
    "                        # Handle invalid JSON format in prediction\n",
    "                        gold_json = json.loads(entry[\"gold\"])\n",
    "                        num_cols = len(gold_json.get(\"colnames\", []))\n",
    "                        pred_cols = [\"???\"] * num_cols\n",
    "\n",
    "                    # Extract and canonicalize ground truth\n",
    "                    gold_json = json.loads(entry[\"gold\"])\n",
    "                    gold_cols = [\n",
    "                        canonical_header(col) for col in gold_json.get(\"colnames\", [])\n",
    "                    ]\n",
    "\n",
    "                    # Handle mismatched column counts\n",
    "                    if len(pred_cols) != len(gold_cols):\n",
    "                        pred_cols = [\"???\"] * len(gold_cols)\n",
    "\n",
    "                    predictions.extend(pred_cols)\n",
    "                    ground_truth.extend(gold_cols)\n",
    "\n",
    "            except (json.JSONDecodeError, KeyError) as e:\n",
    "                print(f\"Error processing line: {e}\")\n",
    "                continue\n",
    "\n",
    "    return np.array(predictions), np.array(ground_truth)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process JSONL file and get canonicalized predictions and truth\n",
    "    preds, truths = extract_predictions_from_jsonl(\"/content/generated_samples.jsonl\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    overall, report = report_gen(preds, truths)\n",
    "\n",
    "    # Save results\n",
    "    with open(\"overall.json\", \"w\") as f:\n",
    "        json.dump(overall, f)\n",
    "    report.to_csv(\"report.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
